{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22eb0579",
   "metadata": {},
   "source": [
    "Build a Bi-LSTM model for Named Entity Recognition (NER) using TensorFlow 2 on a small manually defined dataset. The model predicts tags like PER (person), LOC (location), or O (other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcae8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d16ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[\"john\", \"lives\", \"in\", \"new\", \"york\"],\n",
    "             [\"alice\", \"is\", \"from\", \"paris\"],\n",
    "             [\"bob\", \"visited\", \"london\", \"last\", \"year\"]]\n",
    "\n",
    "labels = [[\"PER\", \"O\", \"O\", \"LOC\", \"LOC\"],\n",
    "          [\"PER\", \"O\", \"O\", \"LOC\"],\n",
    "          [\"PER\", \"O\", \"LOC\", \"O\", \"O\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210e77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build vocabularies\n",
    "\n",
    "word_tokenizer=tf.keras.preprocessing.text.Tokenizer(lower=True,oov_token='UNK')\n",
    "word_tokenizer.fit_on_texts(sentences)\n",
    "X=word_tokenizer.texts_to_sequences(sentences)\n",
    "word_index=word_tokenizer.word_index\n",
    "vocab_size=len(word_index)+1\n",
    "\n",
    "tag_tokenizer=tf.keras.preprocessing.text.Tokenizer(lower=True,oov_token='UNK')\n",
    "tag_tokenizer.fit_on_texts(labels)\n",
    "y=tag_tokenizer.texts_to_sequences(labels)\n",
    "tag_index=tag_tokenizer.word_index\n",
    "num_tags=len(tag_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2218e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sequences\n",
    "max_len=max(len(s) for s in X)\n",
    "X=tf.keras.preprocessing.sequence.pad_sequences(X,maxlen=max_len,padding='post')\n",
    "y=tf.keras.preprocessing.sequence.pad_sequences(y,maxlen=max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccb057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to categorical\n",
    "y_cat=tf.keras.utils.to_categorical(y,num_classes=num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb6c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Bi-LSTM model\n",
    "model=Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size,output_dim=64,input_length=max_len),\n",
    "    layers.Bidirectional(layers.LSTM(64,return_sequences=True)),\n",
    "    layers.TimeDistributed(layers.Dense(num_tags,activation='softmax')) #one output per token\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a71db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe07deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d1303c9d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y_cat,epochs=50,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a006961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predict on new sentence\n",
    "test_sentence=[\"alice\", \"is\", \"from\", \"paris\"]\n",
    "test_seq=word_tokenizer.texts_to_sequences([test_sentence])\n",
    "test_seq=tf.keras.preprocessing.sequence.pad_sequences(test_seq,maxlen=max_len,padding='post')\n",
    "\n",
    "pred=model.predict(test_seq)[0]\n",
    "pred_tags=[list(tag_index.keys())[np.argmax(p) - 1] if np.argmax(p) > 0 else \"PAD\" for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b725c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice → per\n",
      "is → o\n",
      "from → o\n",
      "paris → loc\n"
     ]
    }
   ],
   "source": [
    "for word, tag in zip(test_sentence, pred_tags):\n",
    "    print(f\"{word} → {tag}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
