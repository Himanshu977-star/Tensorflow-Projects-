{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b679d3c1",
   "metadata": {},
   "source": [
    "Use TensorFlow Datasets’ SubwordTextEncoder to build a subword-level tokenizer, then encode and decode sentences for NLP tasks like translation or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0f5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2a526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Sentences\n",
    "corpus=[\n",
    "    \"TensorFlow is an end-to-end open-source platform for machine learning.\",\n",
    "    \"Natural Language Processing is a fascinating field.\",\n",
    "    \"Tokenization is the first step in NLP pipelines.\",\n",
    "    \"Subword tokenization helps with rare words.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e069f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build SubwordTextEncoder from corpus\n",
    "tokenizer=tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    corpus,target_vocab_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8192c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subword vocabulary size: 288\n"
     ]
    }
   ],
   "source": [
    "#Print vocabulary size\n",
    "print(\"Subword vocabulary size:\",tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77a727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode and decode a test sentence\n",
    "test_sentence=\"Subword tokenization is powerful for text models.\"\n",
    "encoded=tokenizer.encode(test_sentence)\n",
    "decoded=tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689779c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Subword tokenization is powerful for text models.\n",
      "Encoded sentence: [27, 4, 1, 144, 143, 151, 133, 146, 134, 149, 140, 64, 17, 148, 133, 152, 148, 64, 141, 143, 132, 133, 140, 147, 78]\n",
      "Decoded sentence: Subword tokenization is powerful for text models.\n"
     ]
    }
   ],
   "source": [
    "#Display results\n",
    "print(\"Original sentence:\",test_sentence)\n",
    "print(\"Encoded sentence:\",encoded)\n",
    "print(\"Decoded sentence:\",decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b2d4df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subword Tokens:\n",
      "['Subword ', 'tokenization ', 'is ', 'p', 'o', 'w', 'e', 'r', 'f', 'u', 'l', ' ', 'for ', 't', 'e', 'x', 't', ' ', 'm', 'o', 'd', 'e', 'l', 's', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSubword Tokens:\")\n",
    "print([tokenizer.decode([token]) for token in encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8975df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types of Tokenization\n",
    "\n",
    "#Type\t                 Example\t                                        Use\n",
    "\n",
    "#Word Tokenization\t    \"NLP is fun\" → [\"NLP\", \"is\", \"fun\"]\t                Basic models\n",
    "\n",
    "#Character Tokenization\t\"fun\" → [\"f\", \"u\", \"n\"]\t                            Language modeling\n",
    "\n",
    "#Subword Tokenization\t\"tokenization\" → [\"token\", \"ization\"]\t            Used in BERT, T5, GPT\n",
    "\n",
    "#Sentence Tokenization\t\"Hello. How are you?\" → [\"Hello.\", \"How are you?\"]\tParagraph understanding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
